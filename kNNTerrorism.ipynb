{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "random.seed(101)\n",
    "model = KeyedVectors.load('model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading our dataset\n",
    "def dataload(file,split,validationSpilt,train=[],validation=[],test=[]):\n",
    "    #print(file)\n",
    "    with open(file,'r') as csvfile:\n",
    "        lines=csv.reader(csvfile)\n",
    "        data=list(lines)\n",
    "    #data = data.dropna(axis=1, how='any')\n",
    "    for x in range(1, len(data)-1):\n",
    "        #print(data[x])\n",
    "        l=data[x]\n",
    "        d = []\n",
    "        for i in l:\n",
    "            if i != '':\n",
    "                d.append(i)\n",
    "        #print(d)\n",
    "        #break\n",
    "        if(x<split):\n",
    "            if(random.random()>validationSpilt):\n",
    "                validation.append(d)\n",
    "            else:\n",
    "                train.append(d)\n",
    "        else:\n",
    "            test.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineDistance(x, y):\n",
    "    #print(length)\n",
    "    #print(len(y))\n",
    "    distance=0\n",
    "    magnitude_x=0\n",
    "    magnitude_y=0\n",
    "    #print(x[0])\n",
    "    #print(y)\n",
    "    product=0\n",
    "    for i in range(0,len(x)):\n",
    "        magnitude_x += x[i]*x[i]\n",
    "    for i in range(0,len(y)):\n",
    "        magnitude_y +=y[i]*y[i]\n",
    "    for i in range(0,len(x)):\n",
    "        product+=x[i]*y[i]\n",
    "    #print(product)\n",
    "    #print(magnitude_x)\n",
    "    #print(magnitude_y)\n",
    "    distance=float(product)/float((math.sqrt(magnitude_x)*math.sqrt(magnitude_y)))\n",
    "    return(1-distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vec(sentence):\n",
    "    words = sentence.split()\n",
    "    word_vecs = [model[w] for w in words]\n",
    "    #print(len(word_vecs))    \n",
    "    #return word_vecs\n",
    "    return (np.array(word_vecs).sum(axis=0)/len(word_vecs)).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "    \"\"\"Takes 2 vectors a, b and returns the cosine similarity according \n",
    "    to the definition of the dot product\n",
    "    \"\"\"\n",
    "    a = np.asarray(a,dtype=float)\n",
    "    b = np.asarray(b,dtype=float)\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    cos = dot_product / (norm_a * norm_b)\n",
    "    return (1-cos)\n",
    "\n",
    "\"\"\"\n",
    "def cleanup(sentence):\n",
    "    trainList=[]\n",
    "    sentence=str(sentence)\n",
    "    print(type(sentence))\n",
    "    train_str=sentence.lower()\n",
    "    words=words=nltk.word_tokenize(train_str)\n",
    "    for word in words:\n",
    "        if (word.isalpha() and not word in stopword_set):\n",
    "            trainList.append(word)\n",
    "    train_str=' '.join(trainList)\n",
    "    return train_str\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(sentence):\n",
    "    trainList=[]\n",
    "    #print(type(sentence))\n",
    "    train_str=sentence.lower()\n",
    "    words=words=nltk.word_tokenize(train_str)\n",
    "    for word in words:\n",
    "        if (not word.isdigit() and not word in stopword_set and re.search('[a-zA-Z]', word)):\n",
    "            #word.translate(None, string.punctuation)\n",
    "            trainList.append(word)\n",
    "    train_str=' '.join(trainList)\n",
    "    #print(train_str)\n",
    "    return train_str\n",
    "\n",
    "def removePunct(word):\n",
    "    # define punctuation\n",
    "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "    # To take input from the user\n",
    "    # my_str = input(\"Enter a string: \")\n",
    "\n",
    "    # remove punctuation from the string\n",
    "    no_punct = \"\"\n",
    "    for char in word:\n",
    "        if char not in punctuations:\n",
    "            no_punct = no_punct + char\n",
    "        else:\n",
    "            no_punct = no_punct + ' '\n",
    "    return no_punct        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullDistFinder(train,test):\n",
    "    noOfColumnsTestSet=len(test)\n",
    "    #print(\"--------------\",noOfColumnsTestSet,\"------------------------\")\n",
    "    trainWithoutTarget=train[:(noOfColumnsTestSet)]\n",
    "    train_num = []\n",
    "    train_str = []\n",
    "    test_num = []\n",
    "    test_str = []\n",
    "\n",
    "    #print(len(test))\n",
    "    #print('**********************************************')\n",
    "    for i in range(0,noOfColumnsTestSet):\n",
    "        if i in [0,1,2,5]:\n",
    "            if trainWithoutTarget[i].isdigit() and test[i].isdigit():\n",
    "                train_num.append(float(trainWithoutTarget[i]))\n",
    "                test_num.append(float(test[i]))\n",
    "        else:\n",
    "            #x=cleanup(train1[i])\n",
    "            if(not trainWithoutTarget[i].isdigit()):\n",
    "                #if(word.isalpha() and not word in stopword_set):\n",
    "                x=cleanup(trainWithoutTarget[i])\n",
    "                x=removePunct(x)\n",
    "                train_str.append(x)\n",
    "\n",
    "            if(not test[i].isdigit()):\n",
    "                x=cleanup(test[i])\n",
    "                x=removePunct(x)\n",
    "                test_str.append(x)\n",
    "\n",
    "    dist1 = cosineDistance(train_num, test_num)\n",
    "    trainS = ' '.join(train_str)\n",
    "    testS = ' '.join(test_str)\n",
    "    dist2 = cosineDistance(average_vec(trainS)[0], average_vec(testS)[0])\n",
    "    #print(dist2)\n",
    "    #return(0)\n",
    "    dist = (dist1 + dist2)/2\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returning K nearest neighbours based on distance\n",
    "def Neighbors(train, test, k):\n",
    "    distances = []\n",
    "    length = len(test)\n",
    "    testWithoutTarget=test[:(length-1)]\n",
    "    for x in range(len(train)):\n",
    "        dist = fullDistFinder(train[x],testWithoutTarget)\n",
    "        distances.append((train[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting the classes obtained from Neighbours\n",
    "def Response(neighbors):\n",
    "    Votes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in Votes:\n",
    "            Votes[response] += 1\n",
    "        else:\n",
    "            Votes[response] = 1\n",
    "    sortedVotes = sorted(Votes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedVotes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Accuracy\n",
    "def Accuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        cleanedTest=cleanup(testSet[x][-1])\n",
    "        cleanedTest=removePunct(cleanedTest)\n",
    "        cleanedPred=cleanup(predictions[x])\n",
    "        cleanedPred=removePunct(cleanedPred)\n",
    "        #print(cleanedTest)\n",
    "        #print(cleanedPred)\n",
    "        testVec=average_vec(cleanedTest)[0]\n",
    "        predVec=average_vec(cleanedPred)[0]\n",
    "        #print(len(testVec))\n",
    "        #print(len(predVec))\n",
    "        distance=cosineDistance(testVec,predVec)\n",
    "        similarity=1-distance\n",
    "        if similarity>=0.95:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Combining all functions to get KNN\n",
    "random.seed(101)\n",
    "trainingSet=[] #training set contains 11 columns with the last column being the target column\n",
    "test=[]        #test set contains 10 columns.\n",
    "validationSet=[]\n",
    "split = 3000\n",
    "validationSplit=0.8\n",
    "dataload('New.csv', split,validationSplit, trainingSet,validationSet, test)\n",
    "#print(trainingSet)\n",
    "#print(test)\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "trainingSet=[x[1:] for x in trainingSet]\n",
    "#trainingSet=trainingSet[:100]\n",
    "validationSet=[x[1:] for x in validationSet]\n",
    "#validationSet=validationSet[:5]\n",
    "test=[x[1:] for x in test]\n",
    "#print(test)\n",
    "#print('Train set: ',trainingSet[0])\n",
    "#print('Validation set: ',validationSet[0][5])\n",
    "#print\n",
    "#print(len(trainingSet))\n",
    "#print(len(validationSet))\n",
    "\n",
    "#k=5\n",
    "predictions=[]\n",
    "resultForAllK=[]\n",
    "predictionsForAllK=[]\n",
    "accuracyForAllK=[]\n",
    "for k in range(1,6):\n",
    "    temp1=[]\n",
    "    temp2=[]\n",
    "    predictions=[]\n",
    "    for x in range(len(validationSet)):\n",
    "        #print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        neighbors = Neighbors(trainingSet, validationSet[x], k)\n",
    "        #print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "        result = Response(neighbors)\n",
    "        temp1.append(result)\n",
    "        predictions.append(result)\n",
    "        #print('Predicted=',result,', Actual=',validationSet[x][-1])\n",
    "    resultForAllK.append(temp1)\n",
    "    predictionsForAllK.append(predictions)\n",
    "    accuracy =Accuracy(validationSet, predictions)\n",
    "    accuracyForAllK.append(accuracy)\n",
    "    print(accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
